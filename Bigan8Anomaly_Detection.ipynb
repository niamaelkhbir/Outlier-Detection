{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"collapsed_sections":["xFg2TAqw6EOl","ML00f50n6Hlo"],"toc_visible":true,"machine_shape":"hm","authorship_tag":"ABX9TyMQcbZ/Z2HIOxtQFnMWPLwF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"P6mbJKBNZ3KT","colab_type":"code","outputId":"ac3e6325-4694-440d-8faa-aac58aa8699c","executionInfo":{"status":"ok","timestamp":1584925211913,"user_tz":-60,"elapsed":36664,"user":{"displayName":"Tharsan Senthivel","photoUrl":"","userId":"17713640806797800736"}},"colab":{"base_uri":"https://localhost:8080/","height":118}},"source":["from google.colab import drive\n","import os \n","\n","drive.mount('/content/gdrive/', force_remount = True)\n","os.chdir(\"/content/gdrive/My Drive/MasterRecherche/Bigan Efficient\")\n","\n","\n","#!python3 train.py"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qa21TZQTjoRX","colab_type":"text"},"source":["#Beginning"]},{"cell_type":"code","metadata":{"id":"Dm5-Hz9I1f3V","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1pCWTxNGd9di","colab_type":"text"},"source":["The results are given for a bigan, we can show the score as follwo\n","\n","\n","now we are going to try a cGAN which is a conditional GAN"]},{"cell_type":"markdown","metadata":{"id":"zYMWJtb4HrKf","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"vqSqXEcYd8kU","colab_type":"code","outputId":"c7fa0f9d-b73b-4368-c400-dcd4de1dba33","executionInfo":{"status":"ok","timestamp":1584925219269,"user_tz":-60,"elapsed":7340,"user":{"displayName":"Tharsan Senthivel","photoUrl":"","userId":"17713640806797800736"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["import argparse\n","import os\n","import random\n","import torch\n","import torch.cuda\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","import torch.optim as optim\n","import torch.utils.data\n","import torchvision.datasets as dset\n","import torchvision.transforms as transforms\n","import torchvision.utils as vutils\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","\n","\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Dataset\n","\n","import lib\n","\n","import os.path\n","\n","\n","# print(os.path.abspath(lib.__file__))\n","\n","from lib.load_data import load_data\n","\n","# https://github.com/MStypulkowski/BiGAN/blob/master/BiGAN.ipynb\n","\n","print(torch.cuda.is_available())\n","\n","ngpu = 4\n","device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n","\n","latent_size = 200\n","\n","criterion = torch.nn.BCEWithLogitsLoss()\n","lr = 1e-5\n","batch_size = 100\n","num_epochs = 5\n","\n","train_loader, test_loader = load_data(batch_size,0,0.7)\n","\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["False\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"R39CWXCrHDbn","colab_type":"text"},"source":["# Generateur, Discriminateur, Encoder\n","\n","dans cette partie nous allons créer les trois parties de notre BIGAN.\n","\n","As input we have MNIST which is a 28x28x1 dataset."]},{"cell_type":"markdown","metadata":{"id":"Xrvd4ERN5teQ","colab_type":"text"},"source":["Define Discriminator\n"]},{"cell_type":"markdown","metadata":{"id":"-qh1PFgD58p_","colab_type":"text"},"source":["# DISCRIMINATOR"]},{"cell_type":"code","metadata":{"id":"z-8_QE3y5tzl","colab_type":"code","colab":{}},"source":["# class Discriminator(nn.Module):\n","#   def __init__(self, ngpu, latent_size):\n","\n","#     super(Discriminator, self).__init__()\n","#     self.ngpu = ngpu\n","#     self.latent_size = latent_size\n","# #for x\n","#     self.input_x= nn.Sequential (\n","#         nn.Conv2d(in_channels= 1,\n","#                   out_channels= 64,\n","#                   kernel_size= 4, #28-5+1=24\n","#                   stride = 2,\n","#                   padding = (4-1)//2),\n","#         nn.LeakyReLU(0.1),\n","#         nn.Conv2d(in_channels= 64,\n","#                   out_channels= 64,\n","#                   kernel_size= 4, #28-3+1=20\n","#                   stride = 2,padding = (4-1)//2),\n","#         nn.BatchNorm2d(64),\n","#         nn.LeakyReLU(0.1),\n","#         )\n","# #for z (d(Z))\n","#     self.input_z= nn.Sequential(\n","#         nn.Linear(latent_size,512),\n","#         nn.LeakyReLU(0.1),\n","#         )\n","\n","# #then we compute d(x,z) by concateantion and we also need the intermediate layer\n","# #for loss Calculation\n","\n","#     #here we compute the intermediate layer value\n","#     self.concaxz = nn.Sequential(\n","#         nn.Linear(3648,1024),\n","#         nn.LeakyReLU(0.01),\n","#     )\n","     \n","#     self.output_discri = nn.Sequential(\n","#     nn.Linear(in_features = 1024,out_features = 1),\n","#     nn.Sigmoid(),\n","#     )\n","    \n","\n","\n","#   def forward(self,z,x):\n","    \n","#     x=x.view(-1,1,28,28)\n","#     output_x= self.input_x(x)\n","#     output_x = output_x.view(-1,7*7*64)\n","    \n","#     output_z = self.input_z(z)\n","    \n","#     output_intermediate_features = self.concaxz(torch.cat([output_x,output_z], dim =1))\n","#     output = self.output_discri(output_intermediate_features)\n","#     return output.squeeze(), output_intermediate_features.view(x.size()[0],-1)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vd2iK8zvgtV1","colab_type":"code","colab":{}},"source":["# netD = Discriminator(ngpu,latent_size).to(device)\n","\n","# netD.apply(weights_init)\n","# print(netD)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rtzkDya_5zsB","colab_type":"text"},"source":["Definissons le discriminator"]},{"cell_type":"markdown","metadata":{"id":"xFg2TAqw6EOl","colab_type":"text"},"source":["#GENERATOR"]},{"cell_type":"code","metadata":{"id":"RbRyRE4e53Ff","colab_type":"code","colab":{}},"source":["# class Generator(nn.Module):\n","#   def __init__(self, ngpu, latent_size):\n","\n","#     super(Generator, self).__init__()\n","#     self.ngpu = ngpu\n","#     self.latent_size = latent_size\n","#     self.dense = nn.Sequential (\n","        \n","#          nn.Linear(latent_size,1024),\n","#          nn.ReLU(True),\n","        \n","# ##définir les inputs genre y ensuite définir le discrimaintaor puis les scores\n","#         nn.Linear(1024,7*7*128),\n","#         #nn.BatchNorm2d(7*7*128),\n","#         nn.ReLU(True)\n","#         )\n","    \n","#     self.convlayer= nn.Sequential(\n","#          nn.ConvTranspose2d(128,\n","#                            out_channels= 64,\n","#                            kernel_size = 4,\n","#                            stride = 2,padding = (4-1)//2),\n","#         nn.BatchNorm2d(64),\n","#         nn.ReLU(True),\n","\n","#         nn.ConvTranspose2d(64,\n","#                            out_channels= 1,\n","#                            kernel_size = 4,\n","#                            stride = 2,padding = (4-1)//2\n","#                            ),\n","#         nn.Tanh()\n","#     )\n","\n","#   def forward(self, input):\n","#     #input = input.view(-1, latent_size)\n","#     # print(\"Generatpr \"+ str(input.shape))\n","#     dense = self.dense(input)\n","#     #print('dense ' +str(dense.shape))\n","#     dense = dense.view(-1,128,7,7)\n","#     output = self.convlayer(dense)\n","#     # print('generator' +str(dense.shape))\n","#     return output\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A1BzUxtO44Tt","colab_type":"code","colab":{}},"source":["# netG = Generator(ngpu,latent_size).to(device)\n","\n","# netG.apply(weights_init)\n","# print(netG)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ML00f50n6Hlo","colab_type":"text"},"source":["# ENCODER"]},{"cell_type":"code","metadata":{"id":"42leagmJHB_Q","colab_type":"code","colab":{}},"source":["# class Encoder(nn.Module):\n","#   def __init__(self,ngpu,latent_size):\n","#     super(Encoder,self).__init__()\n","#     self.latent_size=latent_size\n","#     self.npgu = ngpu\n","#     self.layer_1= nn.Sequential(\n","\n","# #layer 1    \n","#         nn.Conv2d(in_channels= 1, #image is in black and white\n","#                   out_channels= 32,\n","#                   kernel_size= 3,\n","#                   stride = 1,\n","#                   padding = (3-1)//2 ),\n","#         nn.BatchNorm2d(32),\n","#         nn.LeakyReLU(0.1),\n","\n","# #layer 2\n","#         nn.Conv2d(in_channels= 32,\n","#                   out_channels =  64,\n","#                   kernel_size = 3,\n","#                   stride= 2,\n","#                   padding = (3-1)//2),\n","#         nn.BatchNorm2d(64),\n","#         nn.LeakyReLU(0.1),\n","\n","# #layer 3\n","#         nn.Conv2d(64,\n","#                   128,\n","#                   3, \n","#                   stride = 2,\n","#                   padding = (3-1)//2),\n","#         nn.BatchNorm2d(128),\n","#         nn.LeakyReLU(0.1),)\n","\n","\n","\n","#     self.layer_2 = nn.Linear(6272,latent_size)\n","#         # nn.Conv2d(128,latent_size,3),\n","#         # nn.BatchNorm2d(latent_size),\n","#         # nn.LeakyReLU(0.01)\n","    \n","\n","\n","#   def forward(self, input):\n","#     # print(\" ###### \")\n","#     # print(\"Encoder :\")\n","#     # print(input.shape)\n","#     input = input.view(-1,1,28,28)\n","#     output = self.layer_1(input)\n","#     output= output.view(output.size(0),-1)\n","#     output1 = self.layer_2(output)\n","#     # print(output1.shape)\n","#     # print(\" ###### \")\n","    \n","#     return output1   #,output3.view(batch_size, -1), output2.view(batch_size, -1), output1.view(batch_size, -1)\n","\n","\n","    \n","#     #define different layers of encoder"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QfnSPipXLzvA","colab_type":"code","colab":{}},"source":["# netE =Encoder(ngpu,latent_size).to(device)\n","\n","# netE.apply(weights_init)\n","# print(netE)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YE-OGQUJ-0hh","colab_type":"text"},"source":["Let's convert to CUDA\n"]},{"cell_type":"code","metadata":{"id":"L6vP1rvrO0Dq","colab_type":"code","colab":{}},"source":["def tocuda(x):\n","  return x.cuda()\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hve1SsbNXZrD","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nFbMvCJoP35G","colab_type":"code","colab":{}},"source":["def D_loss(Discriminator_Generator, Discriminator_Encoder, eps = 1e-6):\n","  loss = torch.log(Discriminator_Encoder + eps) + torch.log( 1 - Discriminator_Generator+ eps)\n","  return -torch.mean(loss)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bFb5xsY1QYTN","colab_type":"code","colab":{}},"source":["def EG_loss(Discriminator_Generator, Discriminator_Encoder, eps = 1e-6):\n","  loss = torch.log(Discriminator_Generator + eps) + torch.log( 1 - Discriminator_Encoder+ eps)\n","  return -torch.mean(loss)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JUcVz5EGVTO4","colab_type":"code","colab":{}},"source":["# def sigmoid_cross_entropy(A,B):\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"epcyEVoURZoY","colab_type":"text"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"wclkDBeihquJ","colab_type":"code","colab":{}},"source":["def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        nn.init.normal_(m.weight.data, 0.0, 0.02)\n","    elif classname.find('BatchNorm') != -1:\n","        nn.init.normal_(m.weight.data, 1.0, 0.02)\n","        nn.init.constant_(m.bias.data, 0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EQiIaoKfD1i3","colab_type":"code","colab":{}},"source":["# Training Loop\n","\n","alpha = 0.9\n","# netE = Encoder(ngpu,latent_size).to(device)\n","# netG = Generator(ngpu,latent_size).to(device)\n","# netD = Discriminator(ngpu, latent_size).to(device)\n","\n","# netE = tocuda(netE)\n","from lib.model import Encoder, Generator, Discriminator\n","\n","from lib.train_settings import train_settings\n","from lib.train_settings import model_create\n","\n","\n","netE , netG, netD = model_create(ngpu,latent_size,device)\n","\n","netE.apply(weights_init)\n","netG.apply(weights_init)\n","netD.apply(weights_init)\n","\n","criterion = torch.nn.BCEWithLogitsLoss()\n","\n","optimizerG = optim.Adam([{'params' : netE.parameters()},\n","                        {'params' : netG.parameters()}], lr=lr, betas=(0.5, 0.999))\n","\n","optimizerD = optim.Adam(netD.parameters(), lr = lr , betas = (0.5,0.999))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ys5sWFrIfzN","colab_type":"code","outputId":"ecf1f24d-f409-47ea-e102-1f078a21f592","executionInfo":{"status":"ok","timestamp":1584925252406,"user_tz":-60,"elapsed":2508,"user":{"displayName":"Tharsan Senthivel","photoUrl":"","userId":"17713640806797800736"}},"colab":{"base_uri":"https://localhost:8080/","height":115}},"source":["\n","try:\n","    print('j')\n","    netG.load_state_dict(torch.load('./saved_model/generator.pk1'))\n","    print('h')\n","    netE.load_state_dict(torch.load('./saved_model/encoder.pk1'))\n","    netD.load_state_dict(torch.load('./saved_model/discriminator.pk1'))\n","    print('h')\n","    print(\"\\n--------model restored--------\\n\")\n","except:\n","    print(\"\\n--------model not restored--------\\n\")\n","    pass"],"execution_count":5,"outputs":[{"output_type":"stream","text":["j\n","h\n","h\n","\n","--------model restored--------\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"w-WHN65zSK3E","colab_type":"code","outputId":"6bcde91a-8deb-430c-e767-b867d20ab649","executionInfo":{"status":"ok","timestamp":1584920732555,"user_tz":-60,"elapsed":992445,"user":{"displayName":"Tharsan Senthivel","photoUrl":"","userId":"17713640806797800736"}},"colab":{"base_uri":"https://localhost:8080/","height":342}},"source":["for epoch in range (num_epochs):\n","\n","  \n","  loss_D, Loss_R = 0 , 0\n","  \n","  netD.train()\n","  netE.train()\n","  netG.train()\n","\n","  for i, data in enumerate(train_loader) :\n","    if i > 377 :\n","      break\n","    else : \n","      \n","      #print(random_noise)\n","      netD.zero_grad()\n","      netG.zero_grad()\n","      netE.zero_grad()\n","\n","\n","      images, labels = data\n","\n","\n","      # random_noise = 2*(0.02)*torch.rand(images.shape)-1\n","      images = 2*images-1 #+random_noise\n","      images = images.to(device)\n","  \n","      E_x = netE.forward(images) #z_gen\n","\n","      z = 2*torch.rand(batch_size,latent_size) - 1\n","      z = z.to(device)\n","      \n","      Gz = netG.forward(z) #x_gen \n","      \n","\n","      #let's recover the las layer and the output of the discrimintor\n","      D_E , D_E_F_L = netD.forward(E_x,images)\n","      D_G , D_G_F_L = netD.forward(z,Gz)\n","      \n","      #Loss function\n","      loss_DE = torch.mean(criterion(torch.ones_like(D_E), D_E))\n","      loss_DG = torch.mean(criterion(torch.zeros_like(D_G), D_G))\n","      loss_D = loss_DG + loss_DE\n","\n","      loss_G = torch.mean(criterion(torch.ones_like(D_G), D_G))\n","      loss_E = torch.mean(criterion(torch.zeros_like(D_E), D_E))\n","      \n","      #loss_D = torch.mean(abs(D_E_F_L-D_G_F_L))\n","      \n","      # D_loss.append(loss_D)\n","      #Score \n","      \n","      A_x = alpha*loss_D + (1-alpha)*loss_G\n","      \n","      # print(str(epoch) + '  ' + str(loss_G)+'   '+ str(loss_D)+ '   ' +str(A_x))\n","      # optimizerD.zero_grad()\n","      loss_D.backward(retain_graph=True)\n","      optimizerD.step()\n","\n","      # optimizerG.zero_grad()\n","      loss_G.backward()\n","      loss_E.backward()\n","      optimizerG.step()\n","\n","      if i %100 ==0 :\n","            torch.save(netG.state_dict(),'./saved_model/generator.pk1')\n","            torch.save(netD.state_dict(),'./saved_model/discriminator.pk1' )\n","            torch.save(netE.state_dict(),'./saved_model/encoder.pk1' )\n","            print(\"{}th iteration gen_loss: {} dis_loss: {} enc_loss: {} anomaly-score :{}\".format(i,loss_G.data,loss_D.data, loss_E.data,A_x.data))\n","    # v_utils.save_image(gen_fake.data[0:25],\"./result/gen_{}_{}.png\".format(i,j), nrow=5)\n","   \n","    # Anomaly_Score.append(A_x)\n","  "],"execution_count":0,"outputs":[{"output_type":"stream","text":["0th iteration gen_loss: 0.314533531665802 dis_loss: 1.006419062614441 enc_loss: 0.6931470632553101 anomaly-score :0.38372206687927246\n","100th iteration gen_loss: 0.31342393159866333 dis_loss: 1.0064088106155396 enc_loss: 0.6931470632553101 anomaly-score :0.3827224373817444\n","200th iteration gen_loss: 0.3133784532546997 dis_loss: 1.00640869140625 enc_loss: 0.6931470632553101 anomaly-score :0.3826814591884613\n","300th iteration gen_loss: 0.31336188316345215 dis_loss: 1.00640869140625 enc_loss: 0.6931470632553101 anomaly-score :0.38266655802726746\n","0th iteration gen_loss: 0.3133569657802582 dis_loss: 1.00640869140625 enc_loss: 0.6931470632553101 anomaly-score :0.3826621174812317\n","100th iteration gen_loss: 0.3133496344089508 dis_loss: 1.00640869140625 enc_loss: 0.6931470632553101 anomaly-score :0.382655531167984\n","200th iteration gen_loss: 0.3133438527584076 dis_loss: 1.00640869140625 enc_loss: 0.6931470632553101 anomaly-score :0.38265031576156616\n","300th iteration gen_loss: 0.31333962082862854 dis_loss: 1.00640869140625 enc_loss: 0.6931470632553101 anomaly-score :0.38264650106430054\n","0th iteration gen_loss: 0.31333819031715393 dis_loss: 1.00640869140625 enc_loss: 0.6931470632553101 anomaly-score :0.38264521956443787\n","100th iteration gen_loss: 0.3133368194103241 dis_loss: 1.00640869140625 enc_loss: 0.6931470632553101 anomaly-score :0.38264399766921997\n","200th iteration gen_loss: 0.31333205103874207 dis_loss: 1.00640869140625 enc_loss: 0.6931470632553101 anomaly-score :0.38263970613479614\n","300th iteration gen_loss: 0.3133314251899719 dis_loss: 1.00640869140625 enc_loss: 0.6931470632553101 anomaly-score :0.3826391398906708\n","0th iteration gen_loss: 0.31333109736442566 dis_loss: 1.00640869140625 enc_loss: 0.6931470632553101 anomaly-score :0.3826388418674469\n","100th iteration gen_loss: 0.3133293092250824 dis_loss: 1.00640869140625 enc_loss: 0.6931470632553101 anomaly-score :0.38263723254203796\n","200th iteration gen_loss: 0.31332746148109436 dis_loss: 1.00640869140625 enc_loss: 0.6931470632553101 anomaly-score :0.38263556361198425\n","300th iteration gen_loss: 0.3133261799812317 dis_loss: 1.00640869140625 enc_loss: 0.6931470632553101 anomaly-score :0.3826344311237335\n","0th iteration gen_loss: 0.31332576274871826 dis_loss: 1.00640869140625 enc_loss: 0.6931470632553101 anomaly-score :0.3826340436935425\n","100th iteration gen_loss: 0.313323438167572 dis_loss: 1.00640869140625 enc_loss: 0.6931470632553101 anomaly-score :0.38263195753097534\n","200th iteration gen_loss: 0.313323974609375 dis_loss: 1.00640869140625 enc_loss: 0.6931470632553101 anomaly-score :0.38263243436813354\n","300th iteration gen_loss: 0.3133220374584198 dis_loss: 1.00640869140625 enc_loss: 0.6931470632553101 anomaly-score :0.38263067603111267\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uBKC9nENGbUp","colab_type":"code","outputId":"8d7d4034-cb5b-4080-abe6-f67e396b4a4e","executionInfo":{"status":"ok","timestamp":1584925299262,"user_tz":-60,"elapsed":43104,"user":{"displayName":"Tharsan Senthivel","photoUrl":"","userId":"17713640806797800736"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["D_loss = []\n","EG_loss = []\n","Anomaly_Score_test =[]\n","for i, data in enumerate(test_loader) :\n","\n","  images, labels = data\n","  images = 2*images-1\n","  # print(images)\n","  images = images.to(device)\n","\n","  # z = 2*torch.rand(batch_size,latent_size) - 1\n","  # z = z.to(device)\n","\n","  \n","  Z_gen = netE.forward(images)\n","  D_loss.append(Z_gen)\n","  # plt.imshow(Z_gen)\n","  G_reco = netG.forward(Z_gen)\n","\n","  #let's recover the las layer and the output of the discrimintor\n","  D_E , D_E_F_L = netD(Z_gen,images)\n","  D_G , D_G_F_L = netD(Z_gen,G_reco)\n","\n","  #reconstruction loss \n","  loss_R = torch.norm(images - G_reco, p = 1)\n","  loss_D = torch.norm(D_E_F_L-D_G_F_L, p =1)\n","\n","  # D_loss.append(loss_D)\n","  #Score \n","\n","  A_x = alpha*loss_D + (1-alpha)*loss_R\n","\n","  # print(str(loss_R)+'   '+ str(loss_D)+ '   ' +str(A_x))\n","  # print(labels)\n","  print(\"{}th iteration gen_loss: {} dis_loss: {} anomaly_score : {} \".format(i,loss_R.data,loss_D.data, A_x.data))\n"," \n","\n","  Anomaly_Score_test.append(A_x)\n"," \n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["0th iteration gen_loss: 52947.328125 dis_loss: 16808.326171875 anomaly_score : 20422.2265625 \n","1th iteration gen_loss: 53064.7578125 dis_loss: 16821.255859375 anomaly_score : 20445.60546875 \n","2th iteration gen_loss: 53110.71875 dis_loss: 16947.46484375 anomaly_score : 20563.7890625 \n","3th iteration gen_loss: 53088.0078125 dis_loss: 16828.662109375 anomaly_score : 20454.59765625 \n","4th iteration gen_loss: 53272.6953125 dis_loss: 16778.470703125 anomaly_score : 20427.892578125 \n","5th iteration gen_loss: 53269.56640625 dis_loss: 16916.49609375 anomaly_score : 20551.802734375 \n","6th iteration gen_loss: 53034.421875 dis_loss: 16790.85546875 anomaly_score : 20415.2109375 \n","7th iteration gen_loss: 53155.2734375 dis_loss: 16947.833984375 anomaly_score : 20568.578125 \n","8th iteration gen_loss: 53164.3125 dis_loss: 16852.2890625 anomaly_score : 20483.490234375 \n","9th iteration gen_loss: 52746.1328125 dis_loss: 16630.6328125 anomaly_score : 20242.18359375 \n","10th iteration gen_loss: 53185.0234375 dis_loss: 16862.1640625 anomaly_score : 20494.44921875 \n","11th iteration gen_loss: 52902.15625 dis_loss: 16627.33203125 anomaly_score : 20254.814453125 \n","12th iteration gen_loss: 52873.4609375 dis_loss: 16758.646484375 anomaly_score : 20370.126953125 \n","13th iteration gen_loss: 52983.96484375 dis_loss: 16837.21484375 anomaly_score : 20451.890625 \n","14th iteration gen_loss: 53263.6484375 dis_loss: 16874.611328125 anomaly_score : 20513.513671875 \n","15th iteration gen_loss: 52906.71875 dis_loss: 16821.22265625 anomaly_score : 20429.771484375 \n","16th iteration gen_loss: 52937.3125 dis_loss: 16678.234375 anomaly_score : 20304.140625 \n","17th iteration gen_loss: 52976.703125 dis_loss: 16802.40234375 anomaly_score : 20419.83203125 \n","18th iteration gen_loss: 52997.515625 dis_loss: 16672.8984375 anomaly_score : 20305.359375 \n","19th iteration gen_loss: 53097.015625 dis_loss: 16774.986328125 anomaly_score : 20407.189453125 \n","20th iteration gen_loss: 52809.265625 dis_loss: 16808.068359375 anomaly_score : 20408.1875 \n","21th iteration gen_loss: 52868.34375 dis_loss: 16754.677734375 anomaly_score : 20366.044921875 \n","22th iteration gen_loss: 53077.40234375 dis_loss: 16885.7890625 anomaly_score : 20504.94921875 \n","23th iteration gen_loss: 53360.296875 dis_loss: 16889.48046875 anomaly_score : 20536.5625 \n","24th iteration gen_loss: 53022.7890625 dis_loss: 16783.220703125 anomaly_score : 20407.177734375 \n","25th iteration gen_loss: 53025.81640625 dis_loss: 16746.447265625 anomaly_score : 20374.3828125 \n","26th iteration gen_loss: 53032.6640625 dis_loss: 16768.984375 anomaly_score : 20395.3515625 \n","27th iteration gen_loss: 52970.83203125 dis_loss: 16759.505859375 anomaly_score : 20380.638671875 \n","28th iteration gen_loss: 53016.72265625 dis_loss: 16871.267578125 anomaly_score : 20485.8125 \n","29th iteration gen_loss: 53303.4375 dis_loss: 17074.154296875 anomaly_score : 20697.08203125 \n","30th iteration gen_loss: 52830.28125 dis_loss: 16719.041015625 anomaly_score : 20330.1640625 \n","31th iteration gen_loss: 53003.0703125 dis_loss: 16887.47265625 anomaly_score : 20499.03125 \n","32th iteration gen_loss: 53076.40625 dis_loss: 16912.47265625 anomaly_score : 20528.865234375 \n","33th iteration gen_loss: 53232.7734375 dis_loss: 16844.732421875 anomaly_score : 20483.53515625 \n","34th iteration gen_loss: 52925.2578125 dis_loss: 16694.083984375 anomaly_score : 20317.201171875 \n","35th iteration gen_loss: 53139.79296875 dis_loss: 16763.40625 anomaly_score : 20401.044921875 \n","36th iteration gen_loss: 53015.2265625 dis_loss: 16852.525390625 anomaly_score : 20468.794921875 \n","37th iteration gen_loss: 53047.171875 dis_loss: 16895.96484375 anomaly_score : 20511.0859375 \n","38th iteration gen_loss: 52956.4921875 dis_loss: 16794.33984375 anomaly_score : 20410.5546875 \n","39th iteration gen_loss: 52930.21875 dis_loss: 16583.048828125 anomaly_score : 20217.765625 \n","40th iteration gen_loss: 53124.2109375 dis_loss: 16856.73828125 anomaly_score : 20483.486328125 \n","41th iteration gen_loss: 52882.3203125 dis_loss: 16651.01171875 anomaly_score : 20274.142578125 \n","42th iteration gen_loss: 53237.28125 dis_loss: 16979.755859375 anomaly_score : 20605.5078125 \n","43th iteration gen_loss: 53053.03125 dis_loss: 16761.134765625 anomaly_score : 20390.32421875 \n","44th iteration gen_loss: 53005.2109375 dis_loss: 16867.18359375 anomaly_score : 20480.986328125 \n","45th iteration gen_loss: 53067.4609375 dis_loss: 16722.37890625 anomaly_score : 20356.88671875 \n","46th iteration gen_loss: 53216.4140625 dis_loss: 16859.359375 anomaly_score : 20495.064453125 \n","47th iteration gen_loss: 53043.9375 dis_loss: 16914.12109375 anomaly_score : 20527.103515625 \n","48th iteration gen_loss: 53314.359375 dis_loss: 17066.201171875 anomaly_score : 20691.017578125 \n","49th iteration gen_loss: 53177.109375 dis_loss: 16857.65234375 anomaly_score : 20489.59765625 \n","50th iteration gen_loss: 52975.640625 dis_loss: 16800.13671875 anomaly_score : 20417.6875 \n","51th iteration gen_loss: 52951.8828125 dis_loss: 16760.185546875 anomaly_score : 20379.35546875 \n","52th iteration gen_loss: 53113.2265625 dis_loss: 16909.603515625 anomaly_score : 20529.96484375 \n","53th iteration gen_loss: 52938.203125 dis_loss: 16742.744140625 anomaly_score : 20362.2890625 \n","54th iteration gen_loss: 52863.3203125 dis_loss: 16774.4765625 anomaly_score : 20383.359375 \n","55th iteration gen_loss: 53118.890625 dis_loss: 16908.763671875 anomaly_score : 20529.775390625 \n","56th iteration gen_loss: 53012.56640625 dis_loss: 16892.6875 anomaly_score : 20504.67578125 \n","57th iteration gen_loss: 53078.30078125 dis_loss: 16830.0703125 anomaly_score : 20454.892578125 \n","58th iteration gen_loss: 52965.9140625 dis_loss: 16789.67578125 anomaly_score : 20407.298828125 \n","59th iteration gen_loss: 53097.88671875 dis_loss: 16907.140625 anomaly_score : 20526.21484375 \n","60th iteration gen_loss: 52920.140625 dis_loss: 16747.615234375 anomaly_score : 20364.8671875 \n","61th iteration gen_loss: 53073.796875 dis_loss: 16901.736328125 anomaly_score : 20518.94140625 \n","62th iteration gen_loss: 53151.09375 dis_loss: 16928.232421875 anomaly_score : 20550.51953125 \n","63th iteration gen_loss: 52884.640625 dis_loss: 16732.806640625 anomaly_score : 20347.990234375 \n","64th iteration gen_loss: 53100.9140625 dis_loss: 16755.41796875 anomaly_score : 20389.966796875 \n","65th iteration gen_loss: 52931.5234375 dis_loss: 16810.2421875 anomaly_score : 20422.37109375 \n","66th iteration gen_loss: 52980.515625 dis_loss: 16826.06640625 anomaly_score : 20441.51171875 \n","67th iteration gen_loss: 53029.6328125 dis_loss: 16711.412109375 anomaly_score : 20343.234375 \n","68th iteration gen_loss: 52913.79296875 dis_loss: 16794.240234375 anomaly_score : 20406.1953125 \n","69th iteration gen_loss: 52960.83203125 dis_loss: 16834.90625 anomaly_score : 20447.498046875 \n","70th iteration gen_loss: 52822.95703125 dis_loss: 16697.65625 anomaly_score : 20310.1875 \n","71th iteration gen_loss: 52922.140625 dis_loss: 16719.0390625 anomaly_score : 20339.349609375 \n","72th iteration gen_loss: 53283.375 dis_loss: 17008.3125 anomaly_score : 20635.818359375 \n","73th iteration gen_loss: 53234.9296875 dis_loss: 17006.673828125 anomaly_score : 20629.5 \n","74th iteration gen_loss: 53190.17578125 dis_loss: 16850.34375 anomaly_score : 20484.326171875 \n","75th iteration gen_loss: 52885.7890625 dis_loss: 16681.890625 anomaly_score : 20302.28125 \n","76th iteration gen_loss: 53090.90625 dis_loss: 16847.78125 anomaly_score : 20472.09375 \n","77th iteration gen_loss: 52865.953125 dis_loss: 16785.962890625 anomaly_score : 20393.9609375 \n","78th iteration gen_loss: 53105.5703125 dis_loss: 16859.08203125 anomaly_score : 20483.73046875 \n","79th iteration gen_loss: 53239.5390625 dis_loss: 16884.169921875 anomaly_score : 20519.70703125 \n","80th iteration gen_loss: 52959.98828125 dis_loss: 16733.0078125 anomaly_score : 20355.70703125 \n","81th iteration gen_loss: 53245.3515625 dis_loss: 16852.53515625 anomaly_score : 20491.81640625 \n","82th iteration gen_loss: 52943.31640625 dis_loss: 16940.1015625 anomaly_score : 20540.421875 \n","83th iteration gen_loss: 52959.1328125 dis_loss: 16795.19140625 anomaly_score : 20411.5859375 \n","84th iteration gen_loss: 53012.375 dis_loss: 16885.44921875 anomaly_score : 20498.142578125 \n","85th iteration gen_loss: 53115.421875 dis_loss: 16850.470703125 anomaly_score : 20476.96484375 \n","86th iteration gen_loss: 53228.3515625 dis_loss: 16880.4765625 anomaly_score : 20515.263671875 \n","87th iteration gen_loss: 53049.9609375 dis_loss: 16902.513671875 anomaly_score : 20517.2578125 \n","88th iteration gen_loss: 52996.00390625 dis_loss: 16820.654296875 anomaly_score : 20438.189453125 \n","89th iteration gen_loss: 52959.50390625 dis_loss: 16860.685546875 anomaly_score : 20470.56640625 \n","90th iteration gen_loss: 53201.25 dis_loss: 16776.82421875 anomaly_score : 20419.265625 \n","91th iteration gen_loss: 52932.43359375 dis_loss: 16881.62890625 anomaly_score : 20486.708984375 \n","92th iteration gen_loss: 53258.70703125 dis_loss: 16852.62109375 anomaly_score : 20493.228515625 \n","93th iteration gen_loss: 52989.265625 dis_loss: 16832.169921875 anomaly_score : 20447.87890625 \n","94th iteration gen_loss: 53074.15625 dis_loss: 16775.87890625 anomaly_score : 20405.70703125 \n","95th iteration gen_loss: 53276.703125 dis_loss: 16925.1953125 anomaly_score : 20560.345703125 \n","96th iteration gen_loss: 52873.7890625 dis_loss: 16835.208984375 anomaly_score : 20439.06640625 \n","97th iteration gen_loss: 52752.984375 dis_loss: 16639.365234375 anomaly_score : 20250.7265625 \n","98th iteration gen_loss: 53049.1875 dis_loss: 16779.453125 anomaly_score : 20406.42578125 \n","99th iteration gen_loss: 53006.1484375 dis_loss: 16839.916015625 anomaly_score : 20456.5390625 \n","100th iteration gen_loss: 53069.6328125 dis_loss: 16925.185546875 anomaly_score : 20539.630859375 \n","101th iteration gen_loss: 52778.5 dis_loss: 16689.29296875 anomaly_score : 20298.212890625 \n","102th iteration gen_loss: 52880.78125 dis_loss: 16676.341796875 anomaly_score : 20296.78515625 \n","103th iteration gen_loss: 53121.75 dis_loss: 16796.171875 anomaly_score : 20428.73046875 \n","104th iteration gen_loss: 53133.85546875 dis_loss: 16859.08984375 anomaly_score : 20486.56640625 \n","105th iteration gen_loss: 52922.4453125 dis_loss: 16825.5625 anomaly_score : 20435.25 \n","106th iteration gen_loss: 53078.9296875 dis_loss: 16949.408203125 anomaly_score : 20562.359375 \n","107th iteration gen_loss: 53152.21484375 dis_loss: 16975.525390625 anomaly_score : 20593.1953125 \n","108th iteration gen_loss: 52940.1484375 dis_loss: 16798.09375 anomaly_score : 20412.298828125 \n","109th iteration gen_loss: 53007.171875 dis_loss: 16749.955078125 anomaly_score : 20375.67578125 \n","110th iteration gen_loss: 53210.9296875 dis_loss: 16946.052734375 anomaly_score : 20572.541015625 \n","111th iteration gen_loss: 53028.921875 dis_loss: 16814.3125 anomaly_score : 20435.7734375 \n","112th iteration gen_loss: 53049.109375 dis_loss: 16745.78125 anomaly_score : 20376.11328125 \n","113th iteration gen_loss: 52925.1796875 dis_loss: 16721.09375 anomaly_score : 20341.501953125 \n","114th iteration gen_loss: 53151.578125 dis_loss: 16861.162109375 anomaly_score : 20490.203125 \n","115th iteration gen_loss: 52859.28515625 dis_loss: 16716.03125 anomaly_score : 20330.35546875 \n","116th iteration gen_loss: 53044.94140625 dis_loss: 16966.115234375 anomaly_score : 20573.99609375 \n","117th iteration gen_loss: 53088.171875 dis_loss: 16885.74609375 anomaly_score : 20505.98828125 \n","118th iteration gen_loss: 52789.125 dis_loss: 16632.09375 anomaly_score : 20247.796875 \n","119th iteration gen_loss: 52983.5390625 dis_loss: 16767.65625 anomaly_score : 20389.244140625 \n","120th iteration gen_loss: 52975.34375 dis_loss: 16858.384765625 anomaly_score : 20470.080078125 \n","121th iteration gen_loss: 52842.9921875 dis_loss: 16722.646484375 anomaly_score : 20334.681640625 \n","122th iteration gen_loss: 53031.7265625 dis_loss: 16724.28125 anomaly_score : 20355.025390625 \n","123th iteration gen_loss: 53074.2890625 dis_loss: 16843.380859375 anomaly_score : 20466.470703125 \n","124th iteration gen_loss: 52925.9765625 dis_loss: 16712.38671875 anomaly_score : 20333.74609375 \n","125th iteration gen_loss: 53070.0859375 dis_loss: 16821.1796875 anomaly_score : 20446.0703125 \n","126th iteration gen_loss: 52780.875 dis_loss: 16723.375 anomaly_score : 20329.125 \n","127th iteration gen_loss: 52991.578125 dis_loss: 16812.12890625 anomaly_score : 20430.07421875 \n","128th iteration gen_loss: 52985.80859375 dis_loss: 16940.458984375 anomaly_score : 20544.994140625 \n","129th iteration gen_loss: 52871.6015625 dis_loss: 16756.435546875 anomaly_score : 20367.953125 \n","130th iteration gen_loss: 53234.64453125 dis_loss: 16995.765625 anomaly_score : 20619.65234375 \n","131th iteration gen_loss: 53149.2578125 dis_loss: 16932.767578125 anomaly_score : 20554.416015625 \n","132th iteration gen_loss: 52937.328125 dis_loss: 16870.453125 anomaly_score : 20477.140625 \n","133th iteration gen_loss: 52914.5390625 dis_loss: 16720.515625 anomaly_score : 20339.91796875 \n","134th iteration gen_loss: 53072.09765625 dis_loss: 16865.521484375 anomaly_score : 20486.1796875 \n","135th iteration gen_loss: 53088.7265625 dis_loss: 16853.849609375 anomaly_score : 20477.3359375 \n","136th iteration gen_loss: 52967.84375 dis_loss: 16907.818359375 anomaly_score : 20513.8203125 \n","137th iteration gen_loss: 53075.25390625 dis_loss: 16768.30078125 anomaly_score : 20398.99609375 \n","138th iteration gen_loss: 53119.953125 dis_loss: 16957.33984375 anomaly_score : 20573.6015625 \n","139th iteration gen_loss: 52894.96875 dis_loss: 16797.19921875 anomaly_score : 20406.9765625 \n","140th iteration gen_loss: 52970.6171875 dis_loss: 16780.859375 anomaly_score : 20399.8359375 \n","141th iteration gen_loss: 53188.6875 dis_loss: 16909.59375 anomaly_score : 20537.501953125 \n","142th iteration gen_loss: 53105.73046875 dis_loss: 16952.859375 anomaly_score : 20568.146484375 \n","143th iteration gen_loss: 53151.16015625 dis_loss: 16974.4453125 anomaly_score : 20592.1171875 \n","144th iteration gen_loss: 53132.1015625 dis_loss: 16871.83984375 anomaly_score : 20497.865234375 \n","145th iteration gen_loss: 52944.21875 dis_loss: 16911.6015625 anomaly_score : 20514.86328125 \n","146th iteration gen_loss: 53149.91796875 dis_loss: 16903.330078125 anomaly_score : 20527.98828125 \n","147th iteration gen_loss: 53108.640625 dis_loss: 17032.51953125 anomaly_score : 20640.1328125 \n","148th iteration gen_loss: 52888.9921875 dis_loss: 16790.53515625 anomaly_score : 20400.380859375 \n","149th iteration gen_loss: 53052.0859375 dis_loss: 16836.951171875 anomaly_score : 20458.46484375 \n","150th iteration gen_loss: 53201.23828125 dis_loss: 16964.62109375 anomaly_score : 20588.28125 \n","151th iteration gen_loss: 52880.828125 dis_loss: 16806.75 anomaly_score : 20414.15625 \n","152th iteration gen_loss: 53028.1015625 dis_loss: 16869.22265625 anomaly_score : 20485.109375 \n","153th iteration gen_loss: 53117.4140625 dis_loss: 16771.8125 anomaly_score : 20406.373046875 \n","154th iteration gen_loss: 52933.7421875 dis_loss: 16734.69921875 anomaly_score : 20354.603515625 \n","155th iteration gen_loss: 53111.4375 dis_loss: 16833.248046875 anomaly_score : 20461.06640625 \n","156th iteration gen_loss: 52912.1640625 dis_loss: 16673.50390625 anomaly_score : 20297.369140625 \n","157th iteration gen_loss: 53151.13671875 dis_loss: 16894.4921875 anomaly_score : 20520.15625 \n","158th iteration gen_loss: 52986.4375 dis_loss: 16887.947265625 anomaly_score : 20497.796875 \n","159th iteration gen_loss: 53214.5625 dis_loss: 16774.609375 anomaly_score : 20418.60546875 \n","160th iteration gen_loss: 53097.046875 dis_loss: 16825.888671875 anomaly_score : 20453.00390625 \n","161th iteration gen_loss: 52960.203125 dis_loss: 16705.44140625 anomaly_score : 20330.91796875 \n","162th iteration gen_loss: 52987.8046875 dis_loss: 16762.4296875 anomaly_score : 20384.966796875 \n","163th iteration gen_loss: 52778.47265625 dis_loss: 16735.91796875 anomaly_score : 20340.173828125 \n","164th iteration gen_loss: 52731.04296875 dis_loss: 16618.259765625 anomaly_score : 20229.5390625 \n","165th iteration gen_loss: 52977.6796875 dis_loss: 16735.326171875 anomaly_score : 20359.560546875 \n","166th iteration gen_loss: 52914.81640625 dis_loss: 16777.361328125 anomaly_score : 20391.107421875 \n","167th iteration gen_loss: 52699.16796875 dis_loss: 16779.001953125 anomaly_score : 20371.01953125 \n","168th iteration gen_loss: 53009.71875 dis_loss: 16903.5 anomaly_score : 20514.12109375 \n","169th iteration gen_loss: 53082.7734375 dis_loss: 16849.693359375 anomaly_score : 20473.0 \n","170th iteration gen_loss: 52963.203125 dis_loss: 16708.982421875 anomaly_score : 20334.404296875 \n","171th iteration gen_loss: 52863.96875 dis_loss: 16926.54296875 anomaly_score : 20520.28515625 \n","172th iteration gen_loss: 52807.6875 dis_loss: 16667.419921875 anomaly_score : 20281.447265625 \n","173th iteration gen_loss: 52796.0 dis_loss: 16721.466796875 anomaly_score : 20328.919921875 \n","174th iteration gen_loss: 52771.19921875 dis_loss: 16682.10546875 anomaly_score : 20291.015625 \n","175th iteration gen_loss: 52708.6484375 dis_loss: 16678.3203125 anomaly_score : 20281.353515625 \n","176th iteration gen_loss: 52730.421875 dis_loss: 16738.603515625 anomaly_score : 20337.78515625 \n","177th iteration gen_loss: 53111.5703125 dis_loss: 16920.060546875 anomaly_score : 20539.2109375 \n","178th iteration gen_loss: 52860.1171875 dis_loss: 16799.76953125 anomaly_score : 20405.8046875 \n","179th iteration gen_loss: 52963.5546875 dis_loss: 16676.859375 anomaly_score : 20305.52734375 \n","180th iteration gen_loss: 52994.828125 dis_loss: 16789.166015625 anomaly_score : 20409.732421875 \n","181th iteration gen_loss: 52714.3671875 dis_loss: 16636.177734375 anomaly_score : 20243.99609375 \n","182th iteration gen_loss: 52523.53515625 dis_loss: 16586.24609375 anomaly_score : 20179.974609375 \n","183th iteration gen_loss: 52972.75 dis_loss: 16868.9765625 anomaly_score : 20479.353515625 \n","184th iteration gen_loss: 52814.6015625 dis_loss: 16789.775390625 anomaly_score : 20392.2578125 \n","185th iteration gen_loss: 53018.96484375 dis_loss: 16775.00390625 anomaly_score : 20399.3984375 \n","186th iteration gen_loss: 52896.3671875 dis_loss: 16739.96875 anomaly_score : 20355.609375 \n","187th iteration gen_loss: 52974.41015625 dis_loss: 16848.724609375 anomaly_score : 20461.29296875 \n","188th iteration gen_loss: 52927.3359375 dis_loss: 16728.1484375 anomaly_score : 20348.06640625 \n","189th iteration gen_loss: 52910.1875 dis_loss: 16815.490234375 anomaly_score : 20424.958984375 \n","190th iteration gen_loss: 52838.3828125 dis_loss: 16808.390625 anomaly_score : 20411.388671875 \n","191th iteration gen_loss: 52924.8671875 dis_loss: 16710.765625 anomaly_score : 20332.17578125 \n","192th iteration gen_loss: 52981.6015625 dis_loss: 16810.296875 anomaly_score : 20427.42578125 \n","193th iteration gen_loss: 52698.3984375 dis_loss: 16665.326171875 anomaly_score : 20268.6328125 \n","194th iteration gen_loss: 52771.8671875 dis_loss: 16747.7109375 anomaly_score : 20350.126953125 \n","195th iteration gen_loss: 52862.6015625 dis_loss: 16822.298828125 anomaly_score : 20426.328125 \n","196th iteration gen_loss: 53106.76171875 dis_loss: 16811.220703125 anomaly_score : 20440.775390625 \n","197th iteration gen_loss: 52757.328125 dis_loss: 16784.5 anomaly_score : 20381.783203125 \n","198th iteration gen_loss: 53066.1328125 dis_loss: 16811.0703125 anomaly_score : 20436.576171875 \n","199th iteration gen_loss: 52864.1015625 dis_loss: 16781.673828125 anomaly_score : 20389.916015625 \n","200th iteration gen_loss: 53447.90625 dis_loss: 17155.13671875 anomaly_score : 20784.4140625 \n","201th iteration gen_loss: 52808.83203125 dis_loss: 16838.890625 anomaly_score : 20435.884765625 \n","202th iteration gen_loss: 53120.1015625 dis_loss: 16829.037109375 anomaly_score : 20458.142578125 \n","203th iteration gen_loss: 53168.87890625 dis_loss: 16933.4609375 anomaly_score : 20557.001953125 \n","204th iteration gen_loss: 52806.625 dis_loss: 16712.220703125 anomaly_score : 20321.66015625 \n","205th iteration gen_loss: 52879.1875 dis_loss: 16748.66015625 anomaly_score : 20361.712890625 \n","206th iteration gen_loss: 52667.53125 dis_loss: 16699.3984375 anomaly_score : 20296.2109375 \n","207th iteration gen_loss: 52969.83984375 dis_loss: 16833.26171875 anomaly_score : 20446.919921875 \n","208th iteration gen_loss: 52830.28125 dis_loss: 16739.8203125 anomaly_score : 20348.8671875 \n","209th iteration gen_loss: 52919.21875 dis_loss: 16742.96484375 anomaly_score : 20360.58984375 \n","210th iteration gen_loss: 52872.56640625 dis_loss: 16808.44140625 anomaly_score : 20414.853515625 \n","211th iteration gen_loss: 52780.6171875 dis_loss: 16706.30078125 anomaly_score : 20313.732421875 \n","212th iteration gen_loss: 53232.71875 dis_loss: 17017.49609375 anomaly_score : 20639.017578125 \n","213th iteration gen_loss: 53779.12109375 dis_loss: 17153.15234375 anomaly_score : 20815.75 \n","214th iteration gen_loss: 52825.4609375 dis_loss: 16858.19140625 anomaly_score : 20454.91796875 \n","215th iteration gen_loss: 53509.88671875 dis_loss: 17061.27734375 anomaly_score : 20706.138671875 \n","216th iteration gen_loss: 53431.0859375 dis_loss: 16999.34765625 anomaly_score : 20642.521484375 \n","217th iteration gen_loss: 53333.3984375 dis_loss: 17049.201171875 anomaly_score : 20677.62109375 \n","218th iteration gen_loss: 53204.77734375 dis_loss: 16989.87109375 anomaly_score : 20611.361328125 \n","219th iteration gen_loss: 53194.8125 dis_loss: 16988.763671875 anomaly_score : 20609.3671875 \n","220th iteration gen_loss: 53235.71875 dis_loss: 17125.794921875 anomaly_score : 20736.787109375 \n","221th iteration gen_loss: 52999.6171875 dis_loss: 16861.6328125 anomaly_score : 20475.4296875 \n","222th iteration gen_loss: 53305.01171875 dis_loss: 16842.4453125 anomaly_score : 20488.701171875 \n","223th iteration gen_loss: 54803.4609375 dis_loss: 17632.80078125 anomaly_score : 21349.8671875 \n","224th iteration gen_loss: 53786.1796875 dis_loss: 17174.31640625 anomaly_score : 20835.50390625 \n","225th iteration gen_loss: 53470.44140625 dis_loss: 17248.53515625 anomaly_score : 20870.7265625 \n","226th iteration gen_loss: 53200.87109375 dis_loss: 17066.26953125 anomaly_score : 20679.73046875 \n","227th iteration gen_loss: 53394.37890625 dis_loss: 17111.357421875 anomaly_score : 20739.66015625 \n","228th iteration gen_loss: 52554.7734375 dis_loss: 16540.6953125 anomaly_score : 20142.1015625 \n","229th iteration gen_loss: 53868.390625 dis_loss: 17242.84375 anomaly_score : 20905.3984375 \n","230th iteration gen_loss: 53525.50390625 dis_loss: 17131.46875 anomaly_score : 20770.87109375 \n","231th iteration gen_loss: 52873.34375 dis_loss: 16615.056640625 anomaly_score : 20240.884765625 \n","232th iteration gen_loss: 53208.3046875 dis_loss: 16771.322265625 anomaly_score : 20415.01953125 \n","233th iteration gen_loss: 53326.1875 dis_loss: 16778.44140625 anomaly_score : 20433.21484375 \n","234th iteration gen_loss: 53120.6796875 dis_loss: 16847.49609375 anomaly_score : 20474.814453125 \n","235th iteration gen_loss: 53274.3125 dis_loss: 16814.470703125 anomaly_score : 20460.455078125 \n","236th iteration gen_loss: 53315.61328125 dis_loss: 16885.365234375 anomaly_score : 20528.390625 \n","237th iteration gen_loss: 53388.234375 dis_loss: 16898.529296875 anomaly_score : 20547.5 \n","238th iteration gen_loss: 52870.94140625 dis_loss: 16807.80078125 anomaly_score : 20414.115234375 \n","239th iteration gen_loss: 53294.953125 dis_loss: 17116.87890625 anomaly_score : 20734.685546875 \n","240th iteration gen_loss: 54886.796875 dis_loss: 17664.87890625 anomaly_score : 21387.0703125 \n","241th iteration gen_loss: 55105.7109375 dis_loss: 17679.8046875 anomaly_score : 21422.39453125 \n","242th iteration gen_loss: 54396.21875 dis_loss: 17432.08984375 anomaly_score : 21128.50390625 \n","243th iteration gen_loss: 54147.140625 dis_loss: 17240.22265625 anomaly_score : 20930.9140625 \n","244th iteration gen_loss: 53712.75 dis_loss: 17318.03515625 anomaly_score : 20957.505859375 \n","245th iteration gen_loss: 53906.1953125 dis_loss: 17268.201171875 anomaly_score : 20932.0 \n","246th iteration gen_loss: 53735.58203125 dis_loss: 17255.865234375 anomaly_score : 20903.8359375 \n","247th iteration gen_loss: 53995.1875 dis_loss: 17364.119140625 anomaly_score : 21027.2265625 \n","248th iteration gen_loss: 52880.9375 dis_loss: 17045.271484375 anomaly_score : 20628.837890625 \n","249th iteration gen_loss: 53452.703125 dis_loss: 16946.099609375 anomaly_score : 20596.759765625 \n","250th iteration gen_loss: 53382.546875 dis_loss: 17143.908203125 anomaly_score : 20767.771484375 \n","251th iteration gen_loss: 53576.859375 dis_loss: 17092.345703125 anomaly_score : 20740.796875 \n","252th iteration gen_loss: 53756.98828125 dis_loss: 17330.25 anomaly_score : 20972.923828125 \n","253th iteration gen_loss: 53903.25 dis_loss: 17311.01953125 anomaly_score : 20970.2421875 \n","254th iteration gen_loss: 53907.43359375 dis_loss: 17257.875 anomaly_score : 20922.830078125 \n","255th iteration gen_loss: 52823.8984375 dis_loss: 16698.650390625 anomaly_score : 20311.17578125 \n","256th iteration gen_loss: 53212.03515625 dis_loss: 17017.841796875 anomaly_score : 20637.26171875 \n","257th iteration gen_loss: 53817.1484375 dis_loss: 17282.71484375 anomaly_score : 20936.158203125 \n","258th iteration gen_loss: 53539.59765625 dis_loss: 17059.216796875 anomaly_score : 20707.25390625 \n","259th iteration gen_loss: 53381.546875 dis_loss: 17087.857421875 anomaly_score : 20717.2265625 \n","260th iteration gen_loss: 53165.4921875 dis_loss: 16752.1875 anomaly_score : 20393.517578125 \n","261th iteration gen_loss: 53212.578125 dis_loss: 16823.408203125 anomaly_score : 20462.32421875 \n","262th iteration gen_loss: 23030.9765625 dis_loss: 7344.6708984375 anomaly_score : 8913.30078125 \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Uj1Aqzy95T0v","colab_type":"text"},"source":["# AUC"]},{"cell_type":"code","metadata":{"id":"Q8WN6mJerf1Q","colab_type":"code","outputId":"dfc6d708-e1a5-487e-ea6e-3af67ad7bd5b","executionInfo":{"status":"ok","timestamp":1584925333219,"user_tz":-60,"elapsed":3317,"user":{"displayName":"Tharsan Senthivel","photoUrl":"","userId":"17713640806797800736"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["from lib.data_after import do_prc, is_anomalous, Ano_to_list\n","\n","label = []\n","for i, data in enumerate(test_loader) :\n","   images,labels = data\n","   label.append(labels)\n","\n","\n","ano_score = Ano_to_list(Anomaly_Score_test)\n","true_labels = is_anomalous(label,0)\n","prc_auc = do_prc(ano_score,true_labels,file_name= 'results',directory= './results', plot = True)\n","\n","print('The AUC value for '+ str(prc_auc))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["The AUC value for 0.6036199400747927\n"],"name":"stdout"}]}]}